name: Performance Benchmarks

on:
  pull_request:
    branches: [ main ]
  release:
    types: [ published ]
  # Manual trigger for testing
  workflow_dispatch:

jobs:
  benchmark:
    name: Run Performance Benchmarks
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [18.x, 20.x, 22.x, 24.7.x, 25.x]

    steps:
      - uses: actions/checkout@v4
      
      - name: Use Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Build
        run: npm run build
        
      - name: Run benchmarks
        run: |
          # Run benchmark with garbage collection enabled
          npm run benchmark | tee benchmark-results.txt
          
          # Check for critical performance regressions (10MB heap or 2000ms duration)
          if grep -E "Heap Used: [1-9][0-9]+\.[0-9]+ MB|Duration: [2-9][0-9]{3,}" benchmark-results.txt; then
            echo "âš ï¸ Critical performance regression detected! Memory usage exceeds 10MB or duration exceeds 2000ms."
            exit 1
          fi
          
          # Check for minor performance regressions (7MB heap or 1500ms duration)
          if grep -E "Heap Used: [7-9]\.[0-9]+ MB|Duration: 1[5-9][0-9]{2}" benchmark-results.txt; then
            echo "âš ï¸ Minor performance regression detected. Consider optimizing."
            # Don't fail the build for minor regressions
          fi
          
      - name: Store benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-node-${{ matrix.node-version }}
          path: benchmark-results.txt
          
      - name: Comment PR with Results
if: github.event_name == 'pull_request' && matrix.node-version == '24.7.x'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            try {
              const results = fs.readFileSync('benchmark-results.txt', 'utf8');
              
              const comment = `## ðŸ“Š Performance Benchmark Results
              
              \`\`\`
              ${results}
              \`\`\`
              
              > Note: These benchmarks were run on Node.js ${{ matrix.node-version }}
              `;
              
              // Only try to comment if we have a PR number
              if (context.payload.pull_request) {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.name,
                  issue_number: context.payload.pull_request.number,
                  body: comment
                });
                console.log('Successfully posted benchmark results comment');
              } else {
                console.log('No PR number found - skipping comment creation');
                console.log('Benchmark Results:\n', results);
              }
            } catch (error) {
              console.log('Error while trying to post comment:', error.message);
              // Don't fail the build if commenting fails
              if (fs.existsSync('benchmark-results.txt')) {
                console.log('Benchmark Results:\n', fs.readFileSync('benchmark-results.txt', 'utf8'));
              }
            }
